{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os, time, shutil\n",
    "\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.utils import makedirs\n",
    "\n",
    "\n",
    "!rm -f /dev/shm/mx* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MXNET_CUDNN_AUTOTUNE_DEFAULT'] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "600000/5000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 3\n",
    "\n",
    "epochs = 350\n",
    "lr = 0.004\n",
    "per_device_batch_size = 10\n",
    "momentum = 0.9\n",
    "wd = 0.0001\n",
    "\n",
    "lr_factor = 0.75\n",
    "lr_steps = [15, 30, 40, 80,160,250,np.inf]\n",
    "\n",
    "num_gpus = 1\n",
    "num_workers = 4\n",
    "# ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "# ctx = [mx.cpu()]\n",
    "batch_size = per_device_batch_size * max(num_gpus, 1)\n",
    "ctx = [mx.gpu(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[gpu(1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(250),\n",
    "    transforms.RandomResizedCrop((224,224), scale=(0.8, 1.0), ratio=(0.8, 1.2), interpolation=1),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    transforms.RandomFlipTopBottom(),\n",
    "    transforms.RandomBrightness(0.2),\n",
    "    transforms.RandomLighting(0.2),\n",
    "    transforms.RandomContrast(0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    " ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(250),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/xuan/data/AB_PREDICT_RESULT/TESTRESULTFORTRANS/modelData4/'\n",
    "train_path = os.path.join(path, 'TRAIN')\n",
    "val_path = os.path.join(path, 'VAL')\n",
    "test_path = os.path.join(path, 'TEST')\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(train_path).transform_first(transform_train),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(val_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.ImageFolderDataset(test_path).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet50_v2'\n",
    "finetune_net = gluon.model_zoo.vision.get_model(model_name, pretrained=True)\n",
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "# finetune_net.features.initialize(init.Xavier(), ctx = ctx)\n",
    "finetune_net.output.initialize(init.Xavier(), ctx = ctx)\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()\n",
    "\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                        'learning_rate': lr, 'momentum': momentum, 'wd': wd})\n",
    "metric = mx.metric.Accuracy()\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (features): HybridSequential(\n",
       "    (0): BatchNorm(fix_gamma=True, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=3)\n",
       "    (1): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "    (3): Activation(relu)\n",
       "    (4): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
       "    (5): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(64 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=64)\n",
       "        (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=1024)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=1024)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=1024)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=1024)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=1024)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (8): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=1024)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(1024 -> 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=2048)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=2048)\n",
       "        (bn3): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (bn2): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=512)\n",
       "        (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9): BatchNorm(fix_gamma=False, use_global_stats=False, eps=1e-05, momentum=0.9, axis=1, in_channels=2048)\n",
       "    (10): Activation(relu)\n",
       "    (11): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
       "    (12): Flatten\n",
       "  )\n",
       "  (output): Dense(None -> 3, linear)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAll(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()\n",
    "\n",
    "\n",
    "\n",
    "def test0(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        labelForTrue = []\n",
    "        outputsForTrue = []\n",
    "        for idx in range(len(label)):\n",
    "            flag = label[idx].asnumpy() == 0\n",
    "            labelForTrue.append(mx.ndarray.array(label[idx].asnumpy()[flag]))\n",
    "            outputsForTrue.append(mx.ndarray.array(outputs[idx].asnumpy()[flag]))\n",
    "        metric.update(labelForTrue, outputsForTrue)\n",
    "    return metric.get()\n",
    "def test1(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        labelForTrue = []\n",
    "        outputsForTrue = []\n",
    "        for idx in range(len(label)):\n",
    "            flag = label[idx].asnumpy() == 1\n",
    "            labelForTrue.append(mx.ndarray.array(label[idx].asnumpy()[flag]))\n",
    "            outputsForTrue.append(mx.ndarray.array(outputs[idx].asnumpy()[flag]))\n",
    "        metric.update(labelForTrue, outputsForTrue)\n",
    "    return metric.get()\n",
    "\n",
    "\n",
    "def test2(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        labelForTrue = []\n",
    "        outputsForTrue = []\n",
    "        for idx in range(len(label)):\n",
    "            flag = label[idx].asnumpy() == 2\n",
    "            labelForTrue.append(mx.ndarray.array(label[idx].asnumpy()[flag]))\n",
    "            outputsForTrue.append(mx.ndarray.array(outputs[idx].asnumpy()[flag]))\n",
    "        metric.update(labelForTrue, outputsForTrue)\n",
    "    return metric.get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train-acc: 0.716, loss: 0.690 | Val-acc_0: 0.609 |Val-acc_1: 0.649 |Val-acc_2: 0.920|Val-acc_all: 0.784 | time: 56.1\n",
      "[Epoch 1] Train-acc: 0.785, loss: 0.539 | Val-acc_0: 0.376 |Val-acc_1: 0.807 |Val-acc_2: 0.907|Val-acc_all: 0.789 | time: 55.5\n",
      "[Epoch 2] Train-acc: 0.797, loss: 0.509 | Val-acc_0: 0.451 |Val-acc_1: 0.879 |Val-acc_2: 0.868|Val-acc_all: 0.804 | time: 57.0\n",
      "[Epoch 3] Train-acc: 0.823, loss: 0.451 | Val-acc_0: 0.756 |Val-acc_1: 0.766 |Val-acc_2: 0.923|Val-acc_all: 0.847 | time: 56.4\n",
      "[Epoch 4] Train-acc: 0.830, loss: 0.435 | Val-acc_0: 0.808 |Val-acc_1: 0.721 |Val-acc_2: 0.924|Val-acc_all: 0.842 | time: 56.7\n",
      "[Epoch 5] Train-acc: 0.832, loss: 0.454 | Val-acc_0: 0.568 |Val-acc_1: 0.901 |Val-acc_2: 0.770|Val-acc_all: 0.778 | time: 56.3\n",
      "[Epoch 6] Train-acc: 0.842, loss: 0.411 | Val-acc_0: 0.703 |Val-acc_1: 0.850 |Val-acc_2: 0.906|Val-acc_all: 0.855 | time: 57.1\n"
     ]
    }
   ],
   "source": [
    "lr_counter = 0\n",
    "num_batch = len(train_data)\n",
    "resultList = []\n",
    "for epoch in range(epochs):\n",
    "    if epoch == lr_steps[lr_counter]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_factor)\n",
    "        lr_counter += 1\n",
    "\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    metric.reset()\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "#         print(data[0].shape)\n",
    "        with ag.record():\n",
    "            outputs = [finetune_net(X) for X in data]\n",
    "            loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
    "\n",
    "        metric.update(label, outputs)\n",
    "    \n",
    "    _, train_acc = metric.get()\n",
    "    train_loss /= num_batch\n",
    "\n",
    "    _, val_acc_0 = test0(finetune_net, val_data, ctx)\n",
    "    _, val_acc_1 = test1(finetune_net, val_data, ctx)\n",
    "    _, val_acc_2 = test2(finetune_net, val_data, ctx)\n",
    "    _, val_acc_all = testAll(finetune_net, val_data, ctx)\n",
    "    \n",
    "    \n",
    "    print('[Epoch %d] Train-acc: %.3f, loss: %.3f | Val-acc_0: %.3f |Val-acc_1: %.3f |Val-acc_2: %.3f|Val-acc_all: %.3f | time: %.1f' %\n",
    "             (epoch, train_acc, train_loss, val_acc_0,val_acc_1,val_acc_2,val_acc_all, time.time() - tic))\n",
    "\n",
    "    resultList.append((epoch, train_acc, train_loss, val_acc_0,val_acc_1,val_acc_2,val_acc_all, time.time() - tic))\n",
    "    if epoch %5 == 0 :\n",
    "        file_name = \"/xuan/data/AB_PREDICT_RESULT/TESTRESULTFORTRANS/modelData4/model/model_epoch\" +str(epoch) +  \".params\"\n",
    "        finetune_net.save_params(file_name)\n",
    "    \n",
    "_, test_acc = testAll(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))\n",
    "\n",
    "file_name =\"/xuan/data/AB_PREDICT_RESULT/TESTRESULTFORTRANS/modelData4/model/model_final3yinlie.params\"\n",
    "finetune_net.save_params(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Finished] Test-acc_n: 0.752\n",
      "[Finished] Test-acc_t: 0.871\n",
      "[Finished] Test-acc: 0.896\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = test0(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc_n: %.3f' % (test_acc))\n",
    "_, test_acc = test1(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc_t: %.3f' % (test_acc))\n",
    "_, test_acc = testAll(finetune_net, test_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/xuan/detection/data/yinlieData/yinlie_vs_true_padding/model/model_final.params\"\n",
    "finetune_net.save_params(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load 模型参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# finetune_net = gluon.model_zoo.vision.get_model(model_name, pretrained=False)\n",
    "# finetune_net.load_params(file_name,ctx= ctx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "finetune_net = gluon.model_zoo.vision.get_model(model_name, pretrained=False)\n",
    "with finetune_net.name_scope():\n",
    "    finetune_net.output = nn.Dense(classes)\n",
    "finetune_net.load_params(file_name,ctx= ctx[0])\n",
    "\n",
    "import glob\n",
    "data = [ data for data  in  glob.iglob('/xuan/detection/data/yinlieData/yinlie_vs_true_padding/TEST/very_yinlie/*') ]\n",
    "for file in data:\n",
    "    img = cv2.imread(file)\n",
    "    imgaug = transform_test(mx.ndarray.array(img)).expand_dims(axis=0)\n",
    "    imgaug = imgaug.as_in_context(mx.gpu(2))\n",
    "    print(finetune_net(imgaug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(val_data):\n",
    "    data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "    label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10L, 3L, 224L, 224L)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
